# 训练前期 Recall 波动分析

## 问题描述

同一个代码运行两次，前期的 recall 结果有差距，特别是训练初期的波动较大。

## 随机性来源分析

### 1. **数据采样随机性** ⚠️ **主要问题**

**位置**: `src/data_iterator.py`

**问题代码**:
```python
# 第52行：训练时随机采样用户
user_id_list = random.sample(self.users, self.batch_size)

# 第67行：每个用户随机选择正样本位置
k = random.choice(range(4, len(item_list)))
```

**影响**:
- ❌ **这些随机操作没有使用全局随机种子**
- ❌ 即使主程序设置了 `random.seed(SEED)`，DataIterator 的随机性仍然不受控制
- ❌ 每次运行，训练数据的采样顺序都不同
- ❌ 同一个用户的训练样本位置也不同

**波动程度**: 🔴 **高** - 这是导致前期 recall 波动的最主要原因

### 2. **负采样随机性**

**位置**: `src/train.py` - `tf.nn.sampled_softmax_loss`

**问题**:
- `sampled_softmax_loss` 内部使用负采样策略
- 每个 batch 的负样本选择是随机的
- TensorFlow 的随机采样不完全受全局 seed 控制

**影响**:
- 🟡 **中等** - 不同 batch 的负样本分布不同
- 训练初期模型对负样本分布敏感

**代码**:
```python
loss = tf.reduce_mean(
    tf.nn.sampled_softmax_loss(
        weights=weights,
        biases=biases,
        labels=labels,
        inputs=user_vec,
        num_sampled=num_sampled,  # 负样本数量
        num_classes=item_count
    )
)
```

### 3. **模型初始化随机性**

**位置**: `src/model.py`

**问题**:
- Embedding 层使用 `RandomUniform` 初始化
- 虽然设置了 seed，但 TensorFlow 的随机数生成器状态可能不完全一致

**影响**:
- 🟢 **低** - 如果 seed 固定，初始化应该是一致的
- 但在某些情况下（如 GPU 并行），可能会有微小差异

### 4. **TensorFlow 操作级随机性**

**位置**: 各种 TensorFlow 操作

**问题**:
- `@tf.function` 编译时的优化可能导致某些随机操作的顺序改变
- GPU 并行执行时的非确定性

**影响**:
- 🟢 **低** - 通常是微小的数值差异
- 不影响训练趋势

## 波动程度评估

| 随机性来源 | 波动程度 | 影响阶段 | 可控制性 |
|-----------|---------|---------|---------|
| 数据采样随机性 | 🔴 **高** | 整个训练过程 | ✅ 可修复 |
| 负采样随机性 | 🟡 **中** | 训练初期 | ⚠️ 部分控制 |
| 模型初始化 | 🟢 **低** | 训练开始 | ✅ 已控制 |
| TF 操作级随机性 | 🟢 **低** | 持续 | ⚠️ 难以控制 |

## 解决方案

### 方案 1: 修复 DataIterator 的随机性 ⭐ **推荐**

**问题**: DataIterator 的随机操作没有使用全局 seed

**修复方法**:
1. 在 DataIterator 初始化时接受 seed 参数
2. 使用全局 random 对象（已设置 seed）进行采样
3. 或者为 DataIterator 创建独立的 Random 对象并设置 seed

**预期效果**:
- ✅ 每次运行，数据采样顺序一致
- ✅ 前期 recall 波动显著减小
- ✅ 训练结果可复现性大幅提升

### 方案 2: 固定训练数据顺序（用于调试）

**方法**: 对用户列表进行固定排序，按顺序采样而非随机采样

**适用场景**: 调试、对比实验

**缺点**: 可能影响模型性能（数据顺序的重要性）

### 方案 3: 增加随机种子控制

**方法**: 
- 设置 TensorFlow 的确定性模式
- 控制所有随机操作的 seed
- 使用 `tf.config.experimental.enable_op_determinism()`

**适用场景**: 需要完全确定性的训练

**缺点**: 可能降低性能（某些操作必须串行执行）

### 方案 4: 增加负样本数量

**当前配置**:
```python
neg_num = 10
num_sampled = neg_num * batch_size  # 10 * 128 = 1280
```

**建议**:
- 增加到 20-50，减少负采样的随机性影响
- 更多负样本 = 更稳定的训练

**权衡**: 计算成本增加

## 实测建议

### 测试 1: 修复 DataIterator 前后对比

**步骤**:
1. 运行原始代码 3 次，记录前期 recall（前 5 个评估点）
2. 修复 DataIterator 的随机性问题
3. 再次运行 3 次，记录前期 recall
4. 对比波动幅度

**预期结果**:
- 修复前：波动幅度 10-30%
- 修复后：波动幅度 < 5%

### 测试 2: 不同 seed 的影响

**步骤**:
1. 使用不同的 seed（19, 42, 2024）
2. 分别训练，记录 recall 曲线
3. 分析 seed 对最终性能的影响

**预期结果**:
- Seed 主要影响训练路径
- 最终性能应该在合理范围内一致（±2-5%）

### 测试 3: 前期 vs 后期波动对比

**观察点**:
- **前期（iter < 50）**: 波动大，因为模型未收敛
- **后期（iter > 200）**: 波动小，模型已稳定

**原因**:
- 训练初期，随机采样和负采样对模型影响大
- 随着训练进行，模型学到更稳定的表示，对随机性不敏感

## 推荐修复方案

### 优先级 1: 修复 DataIterator ⭐⭐⭐

**为什么最重要**:
- 这是最大的随机性来源
- 最容易修复
- 效果最明显

### 优先级 2: 增加负样本数量 ⭐⭐

**为什么重要**:
- 减少负采样的随机性影响
- 提高训练稳定性
- 可能需要调整学习率

### 优先级 3: 启用 TensorFlow 确定性模式 ⭐

**为什么次要**:
- 性能可能下降
- 但对随机性的改善有限
- 主要用于实验对比

## 实际波动范围

根据经验，正常范围内的波动：

| 训练阶段 | 正常波动范围 | 如果超出可能有问题 |
|---------|-------------|------------------|
| 前 10 次评估 | ±15-30% | > 50% |
| 10-50 次评估 | ±5-10% | > 20% |
| 50+ 次评估 | ±2-5% | > 10% |

## 总结

**主要问题**: DataIterator 的随机采样没有使用全局 seed，导致每次运行的数据顺序不同。

**次要问题**: 负采样的随机性和训练初期模型的敏感性。

**建议行动**:
1. ✅ **立即修复** DataIterator 的随机性问题
2. ⚠️ **考虑增加** 负样本数量（neg_num: 10 → 20-30）
3. 📊 **观察** 修复后的波动是否在合理范围内

**预期改善**:
- 前期 recall 波动：从 ±20-30% → ±5-10%
- 结果可复现性：从不一致 → 一致（相同 seed 下）

