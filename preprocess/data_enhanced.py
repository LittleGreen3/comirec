"""
å¢å¼ºç‰ˆæ•°æ®é¢„å¤„ç†è„šæœ¬
æ”¯æŒè‡ªå®šä¹‰æ•°æ®åˆ†å‰²æ¯”ä¾‹å’Œæ•°æ®é‡‡æ ·
"""
import os
import sys
import json
import random
import argparse
from collections import defaultdict

def parse_args():
    parser = argparse.ArgumentParser(description='æ•°æ®é¢„å¤„ç†å·¥å…·')
    parser.add_argument('dataset', type=str, choices=['book', 'taobao'], 
                       help='æ•°æ®é›†åç§°')
    parser.add_argument('--filter_size', type=int, default=5,
                       help='æœ€å°äº¤äº’æ•°è¿‡æ»¤ï¼ˆé»˜è®¤ï¼š5ï¼‰')
    parser.add_argument('--train_ratio', type=float, default=0.8,
                       help='è®­ç»ƒé›†æ¯”ä¾‹ï¼ˆé»˜è®¤ï¼š0.8ï¼‰')
    parser.add_argument('--valid_ratio', type=float, default=0.1,
                       help='éªŒè¯é›†æ¯”ä¾‹ï¼ˆé»˜è®¤ï¼š0.1ï¼‰')
    parser.add_argument('--test_ratio', type=float, default=None,
                       help='æµ‹è¯•é›†æ¯”ä¾‹ï¼ˆé»˜è®¤ï¼šè‡ªåŠ¨è®¡ç®— = 1 - train_ratio - valid_ratioï¼‰')
    parser.add_argument('--max_users', type=int, default=None,
                       help='æœ€å¤§ç”¨æˆ·æ•°ï¼ˆç”¨äºæ•°æ®é‡‡æ ·ï¼Œé»˜è®¤ï¼šä¸é™åˆ¶ï¼‰')
    parser.add_argument('--seed', type=int, default=1230,
                       help='éšæœºç§å­ï¼ˆé»˜è®¤ï¼š1230ï¼‰')
    parser.add_argument('--stats', action='store_true',
                       help='è¾“å‡ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯')
    
    args = parser.parse_args()
    
    # éªŒè¯æ¯”ä¾‹
    if args.test_ratio is None:
        args.test_ratio = 1.0 - args.train_ratio - args.valid_ratio
    
    total_ratio = args.train_ratio + args.valid_ratio + args.test_ratio
    if abs(total_ratio - 1.0) > 0.001:
        print(f"âš ï¸  è­¦å‘Šï¼šæ¯”ä¾‹æ€»å’Œ = {total_ratio:.3f}ï¼Œä¸ç­‰äº 1.0")
        print(f"   è‡ªåŠ¨å½’ä¸€åŒ–ï¼štrain={args.train_ratio/total_ratio:.3f}, "
              f"valid={args.valid_ratio/total_ratio:.3f}, "
              f"test={args.test_ratio/total_ratio:.3f}")
        args.train_ratio /= total_ratio
        args.valid_ratio /= total_ratio
        args.test_ratio /= total_ratio
    
    return args

def read_from_amazon(source):
    users = defaultdict(list)
    item_count = defaultdict(int)
    
    print(f"æ­£åœ¨è¯»å– Amazon æ•°æ®ï¼š{source}")
    line_count = 0
    with open(source, 'r', encoding='utf-8') as f:
        for line in f:
            r = json.loads(line.strip())
            uid = r['user_id']
            iid = r['asin']
            item_count[iid] += 1
            ts = float(r['timestamp'])
            users[uid].append((iid, ts))
            line_count += 1
            if line_count % 100000 == 0:
                print(f"  å·²è¯»å– {line_count} è¡Œ...")
    
    print(f"âœ… è¯»å–å®Œæˆï¼š{len(users)} ç”¨æˆ·ï¼Œ{len(item_count)} ç‰©å“")
    return users, item_count

def read_from_taobao(source):
    users = defaultdict(list)
    item_count = defaultdict(int)
    
    print(f"æ­£åœ¨è¯»å– Taobao æ•°æ®ï¼š{source}")
    line_count = 0
    with open(source, 'r', encoding='utf-8') as f:
        for line in f:
            conts = line.strip().split(',')
            uid = int(conts[0])
            iid = int(conts[1])
            if conts[3] != 'pv':
                continue
            item_count[iid] += 1
            ts = int(conts[4])
            users[uid].append((iid, ts))
            line_count += 1
            if line_count % 100000 == 0:
                print(f"  å·²è¯»å– {line_count} è¡Œ...")
    
    print(f"âœ… è¯»å–å®Œæˆï¼š{len(users)} ç”¨æˆ·ï¼Œ{len(item_count)} ç‰©å“")
    return users, item_count

def filter_items(items, item_count, filter_size):
    """è¿‡æ»¤äº¤äº’æ•°å°‘äº filter_size çš„ç‰©å“"""
    items = list(items)
    items.sort(key=lambda x: x[1], reverse=True)
    
    item_total = 0
    for index, (iid, num) in enumerate(items):
        if num >= filter_size:
            item_total = index + 1
        else:
            break
    
    item_map = dict(zip([items[i][0] for i in range(item_total)], 
                       list(range(1, item_total+1))))
    
    print(f"ğŸ“Š è¿‡æ»¤åï¼š{item_total} ä¸ªç‰©å“ï¼ˆæœ€å°äº¤äº’æ•° >= {filter_size}ï¼‰")
    return item_map

def filter_users(users, item_map, filter_size):
    """è¿‡æ»¤äº¤äº’æ•°å°‘äº filter_size çš„ç”¨æˆ·"""
    user_ids = list(users.keys())
    filter_user_ids = []
    
    for user in user_ids:
        item_list = users[user]
        index = 0
        for item, timestamp in item_list:
            if item in item_map:
                index += 1
        if index >= filter_size:
            filter_user_ids.append(user)
    
    print(f"ğŸ“Š è¿‡æ»¤åï¼š{len(filter_user_ids)} ä¸ªç”¨æˆ·ï¼ˆæœ€å°äº¤äº’æ•° >= {filter_size}ï¼‰")
    return filter_user_ids

def sample_users(user_ids, max_users, seed):
    """é‡‡æ ·ç”¨æˆ·ï¼ˆå¦‚æœéœ€è¦ï¼‰"""
    if max_users is None or len(user_ids) <= max_users:
        return user_ids
    
    print(f"ğŸ”„ é‡‡æ ·ç”¨æˆ·ï¼š{len(user_ids)} â†’ {max_users}")
    random.seed(seed)
    return random.sample(user_ids, max_users)

def split_users(user_ids, train_ratio, valid_ratio, test_ratio, seed):
    """æŒ‰æ¯”ä¾‹åˆ†å‰²ç”¨æˆ·"""
    random.seed(seed)
    random.shuffle(user_ids)
    
    num_users = len(user_ids)
    split_1 = int(num_users * train_ratio)
    split_2 = int(num_users * (train_ratio + valid_ratio))
    
    train_users = user_ids[:split_1]
    valid_users = user_ids[split_1:split_2]
    test_users = user_ids[split_2:]
    
    print(f"\nğŸ“ æ•°æ®åˆ†å‰²ï¼š")
    print(f"   è®­ç»ƒé›†ï¼š{len(train_users)} ç”¨æˆ· ({train_ratio*100:.1f}%)")
    print(f"   éªŒè¯é›†ï¼š{len(valid_users)} ç”¨æˆ· ({valid_ratio*100:.1f}%)")
    print(f"   æµ‹è¯•é›†ï¼š{len(test_users)} ç”¨æˆ· ({test_ratio*100:.1f}%)")
    
    return train_users, valid_users, test_users

def export_map(name, map_dict):
    """å¯¼å‡ºæ˜ å°„æ–‡ä»¶"""
    with open(name, 'w', encoding='utf-8') as f:
        for key, value in map_dict.items():
            f.write('%s,%d\n' % (key, value))

def export_data(name, user_list, users, item_map, user_map):
    """å¯¼å‡ºæ•°æ®æ–‡ä»¶"""
    total_data = 0
    with open(name, 'w', encoding='utf-8') as f:
        for user in user_list:
            if user not in user_map:
                continue
            item_list = users[user]
            item_list.sort(key=lambda x: x[1])
            index = 0
            for item, timestamp in item_list:
                if item in item_map:
                    f.write('%d,%d,%d\n' % (user_map[user], item_map[item], index))
                    index += 1
                    total_data += 1
    return total_data

def print_statistics(users, item_map, user_map, train_users, valid_users, test_users):
    """è¾“å‡ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
    print("\n" + "="*60)
    print("ğŸ“Š è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯")
    print("="*60)
    
    # ç”¨æˆ·ç»Ÿè®¡
    def get_user_stats(user_list):
        total_interactions = 0
        interaction_counts = []
        for user in user_list:
            if user not in users:
                continue
            count = sum(1 for item, _ in users[user] if item in item_map)
            interaction_counts.append(count)
            total_interactions += count
        return {
            'count': len(user_list),
            'total_interactions': total_interactions,
            'avg_interactions': total_interactions / len(user_list) if user_list else 0,
            'min_interactions': min(interaction_counts) if interaction_counts else 0,
            'max_interactions': max(interaction_counts) if interaction_counts else 0,
        }
    
    train_stats = get_user_stats(train_users)
    valid_stats = get_user_stats(valid_users)
    test_stats = get_user_stats(test_users)
    
    print(f"\nè®­ç»ƒé›†ï¼š")
    print(f"  ç”¨æˆ·æ•°ï¼š{train_stats['count']:,}")
    print(f"  äº¤äº’æ€»æ•°ï¼š{train_stats['total_interactions']:,}")
    print(f"  å¹³å‡äº¤äº’/ç”¨æˆ·ï¼š{train_stats['avg_interactions']:.1f}")
    print(f"  äº¤äº’èŒƒå›´ï¼š{train_stats['min_interactions']} - {train_stats['max_interactions']}")
    
    print(f"\néªŒè¯é›†ï¼š")
    print(f"  ç”¨æˆ·æ•°ï¼š{valid_stats['count']:,}")
    print(f"  äº¤äº’æ€»æ•°ï¼š{valid_stats['total_interactions']:,}")
    print(f"  å¹³å‡äº¤äº’/ç”¨æˆ·ï¼š{valid_stats['avg_interactions']:.1f}")
    print(f"  äº¤äº’èŒƒå›´ï¼š{valid_stats['min_interactions']} - {valid_stats['max_interactions']}")
    
    print(f"\næµ‹è¯•é›†ï¼š")
    print(f"  ç”¨æˆ·æ•°ï¼š{test_stats['count']:,}")
    print(f"  äº¤äº’æ€»æ•°ï¼š{test_stats['total_interactions']:,}")
    print(f"  å¹³å‡äº¤äº’/ç”¨æˆ·ï¼š{test_stats['avg_interactions']:.1f}")
    print(f"  äº¤äº’èŒƒå›´ï¼š{test_stats['min_interactions']} - {test_stats['max_interactions']}")
    
    print(f"\næ€»è®¡ï¼š")
    total_users = train_stats['count'] + valid_stats['count'] + test_stats['count']
    total_interactions = train_stats['total_interactions'] + valid_stats['total_interactions'] + test_stats['total_interactions']
    print(f"  ç”¨æˆ·æ•°ï¼š{total_users:,}")
    print(f"  äº¤äº’æ€»æ•°ï¼š{total_interactions:,}")
    print(f"  å¹³å‡äº¤äº’/ç”¨æˆ·ï¼š{total_interactions/total_users:.1f}")
    print(f"  ç‰©å“æ•°ï¼š{len(item_map):,}")
    
    # ä¼°ç®—è®­ç»ƒæ—¶é—´
    print(f"\nâ±ï¸  é¢„ä¼°è®­ç»ƒæ—¶é—´ï¼ˆåŸºäºé»˜è®¤å‚æ•°ï¼‰ï¼š")
    avg_iterations = train_stats['total_interactions'] / 128  # batch_size=128
    print(f"  ä¸€ä¸ª epoch çº¦éœ€ï¼š{avg_iterations:,.0f} ä¸ª iteration")
    if avg_iterations > 0:
        print(f"  æ¯ 1000 iteration è¯„ä¼°ä¸€æ¬¡ï¼Œçº¦ {avg_iterations/1000:.1f} æ¬¡è¯„ä¼°/epoch")
    print("="*60 + "\n")

def main():
    args = parse_args()
    
    print("="*60)
    print("ğŸš€ æ•°æ®é¢„å¤„ç†å·¥å…·ï¼ˆå¢å¼ºç‰ˆï¼‰")
    print("="*60)
    print(f"æ•°æ®é›†ï¼š{args.dataset}")
    print(f"æœ€å°äº¤äº’æ•°ï¼š{args.filter_size}")
    print(f"æ•°æ®åˆ†å‰²ï¼šè®­ç»ƒ={args.train_ratio:.1%}, "
          f"éªŒè¯={args.valid_ratio:.1%}, "
          f"æµ‹è¯•={args.test_ratio:.1%}")
    if args.max_users:
        print(f"æœ€å¤§ç”¨æˆ·æ•°ï¼š{args.max_users}ï¼ˆé‡‡æ ·ï¼‰")
    print(f"éšæœºç§å­ï¼š{args.seed}")
    print("="*60 + "\n")
    
    # è®¾ç½®éšæœºç§å­
    random.seed(args.seed)
    
    # è¯»å–æ•°æ®
    if args.dataset == 'book':
        source_file = 'Books_5_2023.jsonl'
        if not os.path.exists(source_file):
            print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {source_file}")
            sys.exit(1)
        users, item_count = read_from_amazon(source_file)
    elif args.dataset == 'taobao':
        source_file = 'UserBehavior.csv'
        if not os.path.exists(source_file):
            print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {source_file}")
            sys.exit(1)
        users, item_count = read_from_taobao(source_file)
    
    # è¿‡æ»¤ç‰©å“
    item_map = filter_items(item_count.items(), item_count, args.filter_size)
    
    # è¿‡æ»¤ç”¨æˆ·
    user_ids = filter_users(users, item_map, args.filter_size)
    
    # é‡‡æ ·ç”¨æˆ·ï¼ˆå¦‚æœéœ€è¦ï¼‰
    user_ids = sample_users(user_ids, args.max_users, args.seed)
    
    # åˆ†å‰²æ•°æ®
    train_users, valid_users, test_users = split_users(
        user_ids, args.train_ratio, args.valid_ratio, args.test_ratio, args.seed
    )
    
    # åˆ›å»ºç”¨æˆ·æ˜ å°„
    num_users = len(user_ids)
    user_map = dict(zip(user_ids, list(range(num_users))))
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    if args.stats:
        print_statistics(users, item_map, user_map, train_users, valid_users, test_users)
    
    # ä¿å­˜æ•°æ®
    path = './data/' + args.dataset + '_data/'
    if not os.path.exists(path):
        os.makedirs(path)
        print(f"ğŸ“ åˆ›å»ºç›®å½•ï¼š{path}")
    
    print(f"\nğŸ’¾ ä¿å­˜æ•°æ®...")
    export_map(path + args.dataset + '_user_map.txt', user_map)
    export_map(path + args.dataset + '_item_map.txt', item_map)
    
    total_train = export_data(path + args.dataset + '_train.txt', train_users, 
                             users, item_map, user_map)
    total_valid = export_data(path + args.dataset + '_valid.txt', valid_users,
                             users, item_map, user_map)
    total_test = export_data(path + args.dataset + '_test.txt', test_users,
                            users, item_map, user_map)
    
    print(f"âœ… ä¿å­˜å®Œæˆï¼")
    print(f"   è®­ç»ƒé›†ï¼š{total_train:,} æ¡äº¤äº’")
    print(f"   éªŒè¯é›†ï¼š{total_valid:,} æ¡äº¤äº’")
    print(f"   æµ‹è¯•é›†ï¼š{total_test:,} æ¡äº¤äº’")
    print(f"   æ€»è®¡ï¼š{total_train + total_valid + total_test:,} æ¡äº¤äº’")
    print(f"\nğŸ“‚ æ•°æ®ä¿å­˜ä½ç½®ï¼š{path}")

if __name__ == '__main__':
    main()

